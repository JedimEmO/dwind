use dwind_design_tokens::{parse_tokens, DesignTokenFile, TokenType, TokenValue};
use std::collections::HashMap;
use std::fs;
use std::io::Write;
use std::path::Path;

/// Color utility class prefixes and their corresponding generator macros
const COLOR_UTILITY_PREFIXES: &[(&str, &str)] = &[("bg", "background-color"), ("text", "color")];

/// Dimension utility class prefixes for margin and padding
const DIMENSION_UTILITY_PREFIXES: &[(&str, &str)] = &[
    // Margin utilities
    ("m", "margin"),
    ("ml", "margin-left"),
    ("mr", "margin-right"),
    ("mt", "margin-top"),
    ("mb", "margin-bottom"),
    ("mx", "margin-left,margin-right"),
    ("my", "margin-top,margin-bottom"),
    // Padding utilities
    ("p", "padding"),
    ("pl", "padding-left"),
    ("pr", "padding-right"),
    ("pt", "padding-top"),
    ("pb", "padding-bottom"),
    ("px", "padding-left,padding-right"),
    ("py", "padding-top,padding-bottom"),
];

/// Border radius utility class prefixes
const BORDER_RADIUS_UTILITY_PREFIXES: &[(&str, &str)] = &[
    ("rounded", "border-radius"),
    (
        "rounded-t",
        "border-top-left-radius,border-top-right-radius",
    ),
    (
        "rounded-r",
        "border-top-right-radius,border-bottom-right-radius",
    ),
    (
        "rounded-b",
        "border-bottom-left-radius,border-bottom-right-radius",
    ),
    (
        "rounded-l",
        "border-top-left-radius,border-bottom-left-radius",
    ),
    ("rounded-tl", "border-top-left-radius"),
    ("rounded-tr", "border-top-right-radius"),
    ("rounded-bl", "border-bottom-left-radius"),
    ("rounded-br", "border-bottom-right-radius"),
];

/// Generate Tailwind-like utility classes from a design token file
pub fn render_design_tokens_to_rust_file(
    token_file_path: impl AsRef<Path>,
    output_file_path: impl AsRef<Path>,
) -> Result<(), Box<dyn std::error::Error>> {
    // Parse the design token file
    let token_file_content = fs::read_to_string(token_file_path)?;
    let design_token_file: DesignTokenFile = parse_tokens(&token_file_content)?;

    // Resolve all token expressions first
    let resolved_tokens = resolve_token_expressions(&design_token_file)?;

    // Extract tokens by type
    let color_tokens = extract_color_tokens(&design_token_file, &resolved_tokens);
    let dimension_tokens = extract_dimension_tokens(&design_token_file, &resolved_tokens);
    let border_radius_tokens = extract_border_radius_tokens(&design_token_file, &resolved_tokens);

    // Generate utility classes
    let mut generated_code = String::new();

    // Add header comment
    generated_code.push_str("// Auto-generated utility classes from design tokens\n");
    generated_code.push_str("// Do not edit this file manually\n\n");

    // Generate color utilities
    if !color_tokens.is_empty() {
        generated_code.push_str("// Color utilities\n");
        generated_code.push_str(&generate_color_utility_classes(&color_tokens));
        generated_code.push_str("\n");
    }

    // Generate dimension utilities (margin and padding)
    if !dimension_tokens.is_empty() {
        generated_code.push_str("// Dimension utilities (margin and padding)\n");
        generated_code.push_str(&generate_dimension_utility_classes(&dimension_tokens));
        generated_code.push_str("\n");
    }

    // Generate border radius utilities
    if !border_radius_tokens.is_empty() {
        generated_code.push_str("// Border radius utilities\n");
        generated_code.push_str(&generate_border_radius_utility_classes(
            &border_radius_tokens,
        ));
        generated_code.push_str("\n");
    }

    // Write to output file
    let mut output_file = fs::File::create(output_file_path)?;
    output_file.write_all(generated_code.as_bytes())?;

    Ok(())
}

/// Generate Tailwind-like color utility classes from a design token file (legacy function)
pub fn render_design_token_colors_to_rust_file(
    token_file_path: impl AsRef<Path>,
    output_file_path: impl AsRef<Path>,
) -> Result<(), Box<dyn std::error::Error>> {
    render_design_tokens_to_rust_file(token_file_path, output_file_path)
}

/// Resolve all token expressions in the design token file
pub fn resolve_token_expressions(
    design_token_file: &DesignTokenFile,
) -> Result<HashMap<String, String>, Box<dyn std::error::Error>> {
    let mut resolved = HashMap::new();
    let all_tokens = design_token_file.get_all_tokens();

    // First pass: collect all literal values
    for (path, token) in &all_tokens {
        match &token.value {
            TokenValue::Literal(literal) => {
                resolved.insert(path.clone(), literal.clone());
            }
            TokenValue::Color(color_value) => {
                resolved.insert(path.clone(), color_value.hex.clone());
            }
            _ => {} // Skip expressions for now
        }
    }

    // Second pass: resolve expressions (simple dependency resolution)
    let mut changed = true;
    let mut max_iterations = 10; // Prevent infinite loops

    while changed && max_iterations > 0 {
        changed = false;
        max_iterations -= 1;

        for (path, token) in &all_tokens {
            if resolved.contains_key(path) {
                continue; // Already resolved
            }

            if let TokenValue::Expression(expr) = &token.value {
                // Create a context with both full paths and relative references
                let mut context = resolved.clone();

                // Add relative references for tokens in the same set
                let path_parts: Vec<&str> = path.split('.').collect();
                if path_parts.len() >= 2 {
                    let set_name = path_parts[0];
                    for (full_path, value) in &resolved {
                        let full_path_parts: Vec<&str> = full_path.split('.').collect();
                        if full_path_parts.len() >= 2 && full_path_parts[0] == set_name {
                            // Add relative reference (e.g., "test.a" -> "a")
                            let relative_name = full_path_parts[1..].join(".");
                            context.insert(relative_name, value.clone());
                        }
                    }
                }

                // Try to evaluate the expression
                match expr.evaluate(&context) {
                    Ok(value) => {
                        resolved.insert(path.clone(), value);
                        changed = true;
                    }
                    Err(_) => {
                        // Cannot resolve yet, dependencies not ready
                    }
                }
            }
        }
    }

    Ok(resolved)
}

/// Extract all color tokens from the design token file
fn extract_color_tokens(
    design_token_file: &DesignTokenFile,
    resolved_tokens: &HashMap<String, String>,
) -> Vec<(String, String)> {
    let mut color_tokens = Vec::new();
    let all_tokens = design_token_file.get_all_tokens();

    for (path, token) in all_tokens {
        // Only process color tokens
        if token.token_type != TokenType::Color {
            continue;
        }

        // Get resolved value from the resolved_tokens map
        if let Some(resolved_value) = resolved_tokens.get(&path) {
            color_tokens.push((path, resolved_value.clone()));
        } else {
            eprintln!("Warning: Could not resolve color token '{}'", path);
        }
    }

    color_tokens
}

/// Extract all dimension tokens from the design token file
fn extract_dimension_tokens(
    design_token_file: &DesignTokenFile,
    resolved_tokens: &HashMap<String, String>,
) -> Vec<(String, String)> {
    let mut dimension_tokens = Vec::new();
    let all_tokens = design_token_file.get_all_tokens();

    for (path, token) in all_tokens {
        // Only process dimension tokens
        if token.token_type != TokenType::Dimension {
            continue;
        }

        // Get resolved value from the resolved_tokens map
        if let Some(resolved_value) = resolved_tokens.get(&path) {
            dimension_tokens.push((path, resolved_value.clone()));
        } else {
            eprintln!("Warning: Could not resolve dimension token '{}'", path);
        }
    }

    dimension_tokens
}

/// Extract all border radius tokens from the design token file
fn extract_border_radius_tokens(
    design_token_file: &DesignTokenFile,
    resolved_tokens: &HashMap<String, String>,
) -> Vec<(String, String)> {
    let mut border_radius_tokens = Vec::new();
    let all_tokens = design_token_file.get_all_tokens();

    for (path, token) in all_tokens {
        // Only process border radius tokens
        if token.token_type != TokenType::BorderRadius {
            continue;
        }

        // Get resolved value from the resolved_tokens map
        if let Some(resolved_value) = resolved_tokens.get(&path) {
            border_radius_tokens.push((path, resolved_value.clone()));
        } else {
            eprintln!("Warning: Could not resolve border radius token '{}'", path);
        }
    }

    border_radius_tokens
}

/// Generate Rust code for color utility classes using dwgenerate_map! macro
fn generate_color_utility_classes(color_tokens: &[(String, String)]) -> String {
    let mut output = String::new();

    // Add header comment
    output.push_str("// Auto-generated color utility classes from design tokens\n");
    output.push_str("// Do not edit this file manually\n\n");

    for (prefix, generator_prefix) in COLOR_UTILITY_PREFIXES {
        for (token_path, color_value) in color_tokens {
            let css_rule = format!("{generator_prefix}: {color_value};");
            let utility_name = path_to_class_name(prefix, token_path)
                .to_uppercase()
                .replace("-", "_");
            let utility_prefix = path_to_class_name(prefix, token_path).replace("-", "_");

            output.push_str(&format!(
                "# [doc (hidden)] pub static {utility_name}_RAW: &str = \"{css_rule}\";\n"
            ));
            output.push_str(&format!(
                "#[doc = \"Generated from design token file. class content: {css_rule}\"]\n"
            ));
            output.push_str(&format!("pub static {utility_name}: once_cell::sync::Lazy<String> = once_cell::sync::Lazy::new(|| {{ dominator::class!{{#![prefix=\"{utility_prefix}\"].raw({utility_name}_RAW)}} }});\n"));
        }
    }

    output
}

/// Generate Rust code for dimension utility classes (margin and padding)
fn generate_dimension_utility_classes(dimension_tokens: &[(String, String)]) -> String {
    let mut output = String::new();

    for (prefix, css_properties) in DIMENSION_UTILITY_PREFIXES {
        for (token_path, dimension_value) in dimension_tokens {
            let css_rule = if css_properties.contains(',') {
                // Handle multi-property cases like mx, my, px, py
                let properties: Vec<&str> = css_properties.split(',').collect();
                properties
                    .iter()
                    .map(|prop| format!("{}: {}", prop, dimension_value))
                    .collect::<Vec<_>>()
                    .join("; ")
                    + ";"
            } else {
                format!("{}: {};", css_properties, dimension_value)
            };

            let utility_name = path_to_class_name(prefix, token_path)
                .to_uppercase()
                .replace("-", "_");
            let utility_prefix = path_to_class_name(prefix, token_path).replace("-", "_");

            output.push_str(&format!(
                "# [doc (hidden)] pub static {utility_name}_RAW: &str = \"{css_rule}\";\n"
            ));
            output.push_str(&format!(
                "#[doc = \"Generated from design token file. class content: {css_rule}\"]\n"
            ));
            output.push_str(&format!("pub static {utility_name}: once_cell::sync::Lazy<String> = once_cell::sync::Lazy::new(|| {{ dominator::class!{{#![prefix=\"{utility_prefix}\"].raw({utility_name}_RAW)}} }});\n"));
        }
    }

    output
}

/// Generate Rust code for border radius utility classes
fn generate_border_radius_utility_classes(border_radius_tokens: &[(String, String)]) -> String {
    let mut output = String::new();

    for (prefix, css_properties) in BORDER_RADIUS_UTILITY_PREFIXES {
        for (token_path, border_radius_value) in border_radius_tokens {
            let css_rule = if css_properties.contains(',') {
                // Handle multi-property cases like rounded-t, rounded-r, etc.
                let properties: Vec<&str> = css_properties.split(',').collect();
                properties
                    .iter()
                    .map(|prop| format!("{}: {}", prop, border_radius_value))
                    .collect::<Vec<_>>()
                    .join("; ")
                    + ";"
            } else {
                format!("{}: {};", css_properties, border_radius_value)
            };

            let utility_name = path_to_class_name(prefix, token_path)
                .to_uppercase()
                .replace("-", "_");
            let utility_prefix = path_to_class_name(prefix, token_path).replace("-", "_");

            output.push_str(&format!(
                "# [doc (hidden)] pub static {utility_name}_RAW: &str = \"{css_rule}\";\n"
            ));
            output.push_str(&format!(
                "#[doc = \"Generated from design token file. class content: {css_rule}\"]\n"
            ));
            output.push_str(&format!("pub static {utility_name}: once_cell::sync::Lazy<String> = once_cell::sync::Lazy::new(|| {{ dominator::class!{{#![prefix=\"{utility_prefix}\"].raw({utility_name}_RAW)}} }});\n"));
        }
    }

    output
}

/// Convert token path to CSS class name for dwgenerate_map!
/// Example: "colors.primary.500" -> "colors-primary-500"
fn path_to_class_name(prefix: &str, token_path: &str) -> String {
    let sanitized_path = sanitize_token_path(token_path);
    if prefix.is_empty() {
        sanitized_path.to_lowercase()
    } else {
        format!(
            "{}-{}",
            prefix.to_lowercase(),
            sanitized_path.to_lowercase()
        )
    }
}

/// Sanitize token path for use in CSS class names
/// Convert dots to dashes and handle special characters
fn sanitize_token_path(path: &str) -> String {
    path.replace('.', "_")
        .replace('-', "_")
        .replace(' ', "_")
        .chars()
        .filter(|c| c.is_alphanumeric() || *c == '_')
        .collect()
}

#[cfg(test)]
mod tests {
    use super::*;
    use dwind_design_tokens::{ColorValue, DesignToken, TokenType, TokenValue};
    use std::collections::HashMap;

    #[test]
    fn test_sanitize_token_path() {
        assert_eq!(
            sanitize_token_path("colors.primary.500"),
            "colors_primary_500"
        );
        assert_eq!(
            sanitize_token_path("colors.primary-dark.100"),
            "colors_primary_dark_100"
        );
        assert_eq!(
            sanitize_token_path("colors.text color.50"),
            "colors_text_color_50"
        );
    }

    #[test]
    fn test_extract_color_tokens() {
        let mut sets = HashMap::new();
        let mut test_group = HashMap::new();

        // Add a color token
        test_group.insert(
            "primary".to_string(),
            dwind_design_tokens::TokenNode::Token(DesignToken::new(
                TokenValue::Color(ColorValue {
                    color_space: "srgb".to_string(),
                    components: [1.0, 0.0, 0.0],
                    alpha: 1.0,
                    hex: "#ff0000".to_string(),
                }),
                TokenType::Color,
                Some("Primary color".to_string()),
            )),
        );

        sets.insert(
            "colors".to_string(),
            dwind_design_tokens::TokenNode::Group(test_group),
        );

        let design_token_file = DesignTokenFile {
            sets,
            themes: vec![],
            metadata: dwind_design_tokens::Metadata {
                token_set_order: vec!["colors".to_string()],
                active_themes: vec![],
                active_sets: vec!["colors".to_string()],
            },
        };

        let resolved_tokens = resolve_token_expressions(&design_token_file).unwrap();
        let color_tokens = extract_color_tokens(&design_token_file, &resolved_tokens);
        assert_eq!(color_tokens.len(), 1);
        assert_eq!(color_tokens[0].0, "colors.primary");
        assert_eq!(color_tokens[0].1, "#ff0000");
    }

    #[test]
    fn test_generate_color_utility_classes() {
        let color_tokens = vec![
            ("colors.primary.500".to_string(), "#ff0000".to_string()),
            ("colors.secondary.100".to_string(), "#0000ff".to_string()),
        ];

        let result = generate_color_utility_classes(&color_tokens);

        assert!(result.contains("BG_"));
        assert!(result.contains("TEXT_"));
        assert!(result.contains("colors_primary_500"));
        assert!(result.contains("#ff0000"));
        assert!(result.contains("#0000ff"));
    }
}
